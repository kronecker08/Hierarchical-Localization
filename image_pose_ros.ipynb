{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "##JSS\n",
    "import sys,time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import roslib\n",
    "import rospy\n",
    "import h5py\n",
    "from sensor_msgs.msg import Image\n",
    "import common_function as cf\n",
    "from pathlib import Path\n",
    "import pycolmap\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import logging\n",
    "\n",
    "## superglue ka hai yeh\n",
    "import torch\n",
    "import tqdm\n",
    "from hloc import matchers\n",
    "from hloc.utils.base_model import dynamic_load\n",
    "from hloc.utils.parsers import names_to_pair \n",
    "\n",
    "## localize sfm ka hai\n",
    "from hloc.utils.read_write_model_apna import read_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_pose:   \n",
    "    @torch.no_grad()\n",
    "    def __init__(self,config):\n",
    "        self.subscriber = rospy.Subscriber(\"/camera/image_raw\",\n",
    "                                          Image, self.callback, queue_size=500)       \n",
    "        self.config = config \n",
    "        self.hfnet = cf.HFNet(Path(self.config['model_path']), self.config['outputs'])\n",
    "        self.load_global_descriptors()\n",
    "        Model = dynamic_load(matchers, self.config[\"superglue_config\"][\"model\"][\"name\"])\n",
    "        ## superglue was jumping off too cuda:1 ???\n",
    "        self.device = 'cuda:0'\n",
    "        self.superglue_model = Model(self.config[\"superglue_config\"][\"model\"]).eval().to(self.device)\n",
    "        self.load_local_descriptors()\n",
    "        self.load_map()\n",
    "        camera_model, width, height, params = self.config[\"camera_params\"]\n",
    "        self.camera_params = {\n",
    "                        'model': camera_model,\n",
    "                        'width': width,\n",
    "                        'height': height,\n",
    "                        'params': params,\n",
    "                    }\n",
    "        \n",
    "    def load_map(self):\n",
    "        assert Path(self.config[\"sfm_dir\"]).exists(), Path(self.config[\"sfm_dir\"])\n",
    "#         logging.info('Reading 3D model...')\n",
    "        _, self.db_images, self.points3D = read_model(str(self.config[\"sfm_dir\"]), '.bin')\n",
    "        print(\"read model\")\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def load_local_descriptors(self):\n",
    "        local_feature_path = Path(self.config[\"output_path\"])/\"local_feature.h5\"\n",
    "        self.local_feature_file = h5py.File(str(local_feature_path),\"r\")        \n",
    "        \n",
    "        \n",
    "    def load_global_descriptors(self):\n",
    "        global_feature_path = Path(self.config[\"output_path\"])/\"global_features.h5\"\n",
    "        global_feature_file= h5py.File(str(global_feature_path),\"r\")\n",
    "        self.global_feature_dict = {}\n",
    "        for i,j in enumerate(list(global_feature_file.keys())):\n",
    "            des = global_feature_file[j][\"global_descriptor\"].__array__()\n",
    "            if i == 0:\n",
    "                self.global_matrix = des\n",
    "            else:\n",
    "                self.global_matrix = np.vstack((self.global_matrix, des))\n",
    "            self.global_feature_dict[i] = {\"name\":j, \"descriptor\": des}\n",
    "    \n",
    "    def callback(self, image_data):\n",
    "        self.start_time = time.time()\n",
    "        self.cv_image = np.frombuffer(image_data.data, dtype=np.uint8).reshape(image_data.height, image_data.width, -1)\n",
    "        self.cv_image = cv2.cvtColor(self.cv_image, cv2.COLOR_BGR2RGB)\n",
    "        self.descriptors()\n",
    "    \n",
    "    def descriptors(self):\n",
    "        self.db = self.hfnet.inference((self.cv_image).astype(float))\n",
    "        self.image_size = np.array(self.cv_image.shape[:2][::-1])\n",
    "        self.global_descriptors = self.db[\"global_descriptor\"]\n",
    "        self.keypoints = self.db[\"keypoints\"]\n",
    "        self.local_descriptors = np.transpose(self.db[\"local_descriptors\"])\n",
    "        self.scores = self.db[\"scores\"]\n",
    "        self.find_global_matches()\n",
    "    \n",
    "    def find_global_matches(self):\n",
    "        neighbours = cf.compute_distance(self.global_descriptors, self.global_matrix)\n",
    "        global_matches = ((np.argsort(neighbours)[:self.config[\"global_matches\"]]))\n",
    "        self.global_matches_name = []\n",
    "        for i in global_matches:\n",
    "            name = self.global_feature_dict[i][\"name\"]\n",
    "            self.global_matches_name.append(name)\n",
    "        self.find_superglue_matches()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def find_superglue_matches(self):\n",
    "        self.match_dict = {}\n",
    "        batches = {}\n",
    "        for i in range(0,self.config[\"global_matches\"], self.config[\"batch_size\"]):\n",
    "            batches[i] = self.global_matches_name[i:i+self.config[\"batch_size\"]]\n",
    "        for i in batches:\n",
    "            names = batches[i]\n",
    "            kplist0 = []\n",
    "            kplist1 = []\n",
    "            desc0 = []\n",
    "            desc1 = []\n",
    "            sc0 = []\n",
    "            sc1 = []\n",
    "            for j in names:\n",
    "                pair = names_to_pair(\"query\", j)\n",
    "                feats1 = self.local_feature_file[j]\n",
    "                kplist0.append(self.keypoints)\n",
    "                kplist1.append(feats1[\"keypoints\"].__array__())\n",
    "                desc0.append(self.local_descriptors)\n",
    "                desc1.append(feats1[\"descriptors\"].__array__())\n",
    "                sc0.append(self.scores)\n",
    "                sc1.append(feats1[\"scores\"].__array__())\n",
    "            # pad feature0 not necessary\n",
    "            size_list=[n.shape[0] for n in kplist1]\n",
    "            max_size = np.max(size_list)\n",
    "            kplist1 = [ np.concatenate((n, np.zeros((max_size-n.shape[0], n.shape[1]))), axis=0) for n in kplist1]\n",
    "            desc1 = [ np.concatenate((n, np.zeros((n.shape[0], max_size-n.shape[1]))), axis=1) for n in desc1]\n",
    "            sc1 = [ np.concatenate((n, np.zeros((max_size-n.shape[0]))), axis=0) for n in sc1]\n",
    "            data = {'keypoints0':kplist0, 'descriptors0':desc0, 'scores0':sc0,'keypoints1':kplist1, 'descriptors1':desc1, 'scores1':sc1}\n",
    "            data = {k: torch.from_numpy(np.array(v)).float().to(self.device) for k, v in data.items()}\n",
    "            # some matchers might expect an image but only use its size\n",
    "            data['image0'] = torch.empty((len(sc0), 1,)+tuple(self.image_size)[::-1])\n",
    "            data['image1'] = torch.empty((len(sc0), 1,)+tuple(feats1['image_size'])[::-1])\n",
    "            pred = self.superglue_model(data)\n",
    "            index = 0 \n",
    "            for k in names:\n",
    "#                 pair = names_to_pair(\"query\", k)\n",
    "                Matches = pred[\"matches0\"][index].cpu().short().numpy()\n",
    "                if 'matching_scores0' in pred:\n",
    "                    Scores = pred['matching_scores0'][index].cpu().half().numpy()\n",
    "                self.match_dict[k] = {\"scores\":Scores, \"matches\":Matches}\n",
    "                index+=1 \n",
    "        self.find_pose()\n",
    "        \n",
    "    def find_pose(self):\n",
    "        kp_idx_to_3D = defaultdict(list)\n",
    "        kp_idx_to_3D_to_db = defaultdict(lambda:defaultdict(list))\n",
    "        num_matches = 0\n",
    "        for i,db_name in enumerate(self.global_matches_name):\n",
    "            db_id = self.db_images[db_name].id\n",
    "            points3D_ids = self.db_images[db_name].point3D_ids\n",
    "            matches = self.match_dict[db_name]['matches']\n",
    "            valid = np.where(matches>-1)[0] # the ones which were matched\n",
    "            valid = valid[points3D_ids[matches[valid]]!=-1]\n",
    "            num_matches +=len(valid)\n",
    "            \n",
    "            for idx in valid:\n",
    "                id_3D = points3D_ids[matches[idx]]\n",
    "                kp_idx_to_3D_to_db[idx][id_3D].append(i)\n",
    "                # avoid duplicate observations\n",
    "                if id_3D not in kp_idx_to_3D[idx]:\n",
    "                    kp_idx_to_3D[idx].append(id_3D)\n",
    "                    \n",
    "        idxs = list(kp_idx_to_3D.keys())\n",
    "        mkp_idxs = [i for i in idxs for _ in kp_idx_to_3D[i]]\n",
    "        mkpq = self.keypoints[mkp_idxs]\n",
    "        mkpq = mkpq.astype('float64')\n",
    "        mkpq += 0.5  # COLMAP coordinates\n",
    "        mp3d_ids = [j for i in idxs for j in kp_idx_to_3D[i]]\n",
    "        mp3d = [self.points3D[j].xyz for j in mp3d_ids]\n",
    "        mp3d = np.array(mp3d).reshape(-1, 3)\n",
    "        ret = pycolmap.absolute_pose_estimation(mkpq, mp3d, self.camera_params, self.config[\"ransac_thresh\"])\n",
    "        if ret[\"success\"]:\n",
    "            poses = (ret[\"qvec\"], ret[\"tvec\"])\n",
    "            tvec = cf.colmap_to_global(ret[\"tvec\"], ret[\"qvec\"])\n",
    "            print(tvec)\n",
    "            print(time.time()- self.start_time)\n",
    "#             print(poses)\n",
    "        else:\n",
    "            print(\"Failed\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'model_path':\"/home/Hierarchical-Localization/hfnet/model/saved_models/hfnet\",\n",
    "          'outputs': ['global_descriptor', 'keypoints', 'local_descriptors', 'scores'],\n",
    "          'output_path':\"/home/Hierarchical-Localization/outputs/model_T3_localizedT4\",\n",
    "          \"global_matches\":5,\n",
    "          \"batch_size\":5,\n",
    "          'superglue_config':{'model': {'name': 'superglue', 'weights': 'outdoor', 'sinkhorn_iterations': 50}},\n",
    "          \"ransac_thresh\":12,\n",
    "          \"sfm_dir\":\"/home/Hierarchical-Localization/outputs/model_T3_localizedT4/sfm_superpoint+superglue/geo_registered_model\",\n",
    "          \"camera_params\":(\"SIMPLE_RADIAL\", 640, 480, (658.503, 320, 180, 0.0565491))}\n",
    "def main(config):\n",
    "    ic = image_pose(config)\n",
    "    rospy.init_node(\"image_pose\", anonymous=True)\n",
    "    rospy.spin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
